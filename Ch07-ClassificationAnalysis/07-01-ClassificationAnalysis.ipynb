{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roitraining/PythonML/blob/Development/Ch07-ClassificationAnalysis/07-01-ClassificationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DftlMhfXlhNI"
   },
   "source": [
    "## Combine the multiple files into one big CSV since we could not load a large file to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U79c08g9lhNK"
   },
   "outputs": [],
   "source": [
    "! ./combine.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCx-mtOzlhNP"
   },
   "source": [
    "### Read in a set of data and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYKsqCNglhNR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362620, 11) Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
      "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
      "       'isFlaggedFraud'],\n",
      "      dtype='object')\n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n",
      "0    6354407\n",
      "1       8213\n",
      "Name: isFraud, dtype: int64\n",
      "CASH_OUT    2237500\n",
      "PAYMENT     2151495\n",
      "CASH_IN     1399284\n",
      "TRANSFER     532909\n",
      "DEBIT         41432\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CreditCardFraud.csv')\n",
    "\n",
    "print (df.shape, df.columns)\n",
    "train_size = .3\n",
    "test_size = .1\n",
    "\n",
    "print (df.head())\n",
    "print (df.isFraud.value_counts())\n",
    "print (df.type.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mn1AZlPlhNW"
   },
   "source": [
    "### Keep the columns we want and change the type to code numbers instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz3S1g6elhNX"
   },
   "outputs": [],
   "source": [
    "columns = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'isFraud']\n",
    "df = df[columns]\n",
    "df.type = pd.Categorical(df.type).codes\n",
    "print (df.shape, df.columns)\n",
    "print (df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKQQPPfflhNb"
   },
   "source": [
    "### Prepare train & test sets with desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oF8rjfsJlhNd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "trainX, testX, trainY, testY = train_test_split(df[df.columns[:-1]], df.isFraud, train_size = train_size, test_size = test_size)\n",
    "print (testY.value_counts())\n",
    "print(trainY.value_counts()/trainY.count())\n",
    "print(testY.value_counts()/testY.count())\n",
    "print (trainX[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kusVp-VnlhNg"
   },
   "source": [
    "## Create a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOMjiVP9lhNh"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelNB = GaussianNB()\n",
    "modelNB.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIHKzxzrlhNm"
   },
   "source": [
    "### Examine the results of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu9BVBrrlhNo"
   },
   "outputs": [],
   "source": [
    "predY = modelNB.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "\n",
    "# helper function to print confusion matrix as percentages\n",
    "def cm_percent(cm, length, legend = True):\n",
    "    import numpy as np\n",
    "    if legend:\n",
    "       print (' PC', 'FP\\n', 'FN', 'PW')\n",
    "    return np.ndarray(shape = (2,2), buffer = np.array([100 *(cm[0][0] + cm[1][1])/length,\n",
    "       100 * cm[0][1]/length, 100 * cm[1][0]/length, 100 * (cm[1][0] + cm[0][1])/length]))\n",
    "\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n",
    "print (testY.value_counts())\n",
    "print (len(testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9_n3marlhNs"
   },
   "source": [
    "## Save a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7Zr_8WklhNt"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(modelNB, 'modelNB.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJWFouMwlhNw"
   },
   "source": [
    "## Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMBMLAFOlhNy"
   },
   "outputs": [],
   "source": [
    "modelNB2 = load('modelNB.joblib')\n",
    "predY = modelNB2.predict(testX)\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnIYVeFzlhN3"
   },
   "source": [
    "## Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIMBWf5zlhN5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(trainX, trainY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6EblXsClhN8"
   },
   "source": [
    "## Examine the results of the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB47qZLplhN-"
   },
   "outputs": [],
   "source": [
    "def important_features(model, columns):\n",
    "    return pd.DataFrame(model.feature_importances_, columns=['Importance'], index = columns).sort_values(['Importance'], ascending = False)\n",
    " \n",
    "predY = modelDT.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "print (cm_percent(cm, len(testY)))\n",
    "print (testY.value_counts(), len(testY))\n",
    "print (important_features(modelDT, trainX.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEVweEHXlhOB"
   },
   "source": [
    "## Create and train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "To_f6JTWlhOC"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lycJ3JJZlhOI"
   },
   "source": [
    "## Test the accuracy of the predictions and examine important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4yKn4pklhOJ"
   },
   "outputs": [],
   "source": [
    "predY = modelRF.predict(testX)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=trainX.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Iqv4i89lhOM"
   },
   "source": [
    "## Visualize important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLly66iulhON"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bGX1pYklhOR"
   },
   "source": [
    "## Try removing less important features and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtPKVlDKlhOS"
   },
   "outputs": [],
   "source": [
    "newTrainX = trainX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "newTestX = testX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(newTrainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhtCXClKlhOY"
   },
   "source": [
    "### In this case the accuracy did not go up, but in many cases it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhFbYZ2slhOa"
   },
   "outputs": [],
   "source": [
    "predY = modelRF.predict(newTestX)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=newTrainX.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFqHSW1nlhOd"
   },
   "source": [
    "## Prepare the data\n",
    "### Logistic Regression requires categorical data be dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRaTpXWMlhOe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "def dummy_code(data, columns, drop_first = True):\n",
    "    for c in columns:\n",
    "        dummies = pd.get_dummies(data[c], prefix = c, drop_first = drop_first)\n",
    "        i = list(data.columns).index(c)\n",
    "        data = pd.concat([data.iloc[:,:i], dummies, data.iloc[:,i+1:]], axis = 1)\n",
    "    return data\n",
    "\n",
    "df2 = dummy_code(df, ['type'], drop_first = True)\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "print (testX.columns)\n",
    "print (testX.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jje5i7zlhOn"
   },
   "source": [
    "## Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hcmFoNIlhOq"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "modelLR.fit(trainX, trainY)\n",
    "print(modelLR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQBvfbCilhOt"
   },
   "source": [
    "## Examine the results of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7gJdlFelhOu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "predY = modelLR.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "score = modelLR.score(testX, testY)\n",
    "mse = np.mean((predY - testY)**2)\n",
    "print (score, mse)\n",
    "\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n",
    "\n",
    "predY1 = modelLR.predict_proba(testX)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "roc = roc_auc_score(testY, predY)\n",
    "fpr, tpr, x = roc_curve(testY, predY1[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label = 'AUC = ' + str(roc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#import scikitplot.metrics as skplt\n",
    "#import matplotlib.pyplot as plt\n",
    "#skplt.plot_roc(testY, predY1)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTgCGR1XlhOy"
   },
   "source": [
    "## Try Logistic Regression with different probability thresholds to change ratio of false negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CcSOW6YlhOz"
   },
   "outputs": [],
   "source": [
    "predY = modelLR.predict_proba(testX)\n",
    "print (predY[:10])\n",
    "print ('Score', modelLR.score(testX, testY))\n",
    "\n",
    "for threshold in range(30, 91, 10):\n",
    "    predY1 = np.where(predY[:,1] >= threshold/100, 1, 0)\n",
    "    mse = np.mean((predY1 - testY)**2)\n",
    "    cm = confusion_matrix(testY, predY1)\n",
    "    print ('\\nTHRESHOLD', threshold, 'MSE', mse)\n",
    "    print (cm)\n",
    "    print (cm_percent(cm, len(testY), legend = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2zNQoQblhO6"
   },
   "source": [
    "## Prepare the data for a Neural Network\n",
    "### This time you should not drop the first column when dummy encoding. Additionally, data works better if it is rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W28T7EjClhO7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "# rescale the data\n",
    "df2 = dummy_code(df, ['type'], drop_first = False)\n",
    "print (df2.columns)\n",
    "df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] /= df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']].max()\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcfBRlA8lhPC"
   },
   "source": [
    "## Create a Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HnUlj-TlhPD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
    "modelNN.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyo1DTHYlhPJ"
   },
   "source": [
    "## Examine the results of Neural Network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WD0s5Z0lhPL"
   },
   "outputs": [],
   "source": [
    "predY = modelNN.predict(testX)\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SWOc1o2lhPO"
   },
   "source": [
    "## Create a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNuyggKylhPQ"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "train_size = .03\n",
    "test_size = .01\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "def do_SVM(kernel, gamma):\n",
    "    print (\"\\nKernel:\", kernel, \"Gamma:\", gamma)\n",
    "    modelSVM = svm.SVC(gamma = gamma,  kernel = kernel)\n",
    "    modelSVM.fit(trainX, trainY)\n",
    "    print (modelSVM.score(testX, testY))\n",
    "\n",
    "    predY = modelSVM.predict(testX)\n",
    "    cm = confusion_matrix(testY, predY)\n",
    "    print (cm)\n",
    "\n",
    "do_SVM('linear', gamma='auto')\n",
    "\n",
    "for kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "    for gamma in ['auto', 10, 100]:\n",
    "        if not (kernel == 'poly' and gamma == 100):\n",
    "           do_SVM(kernel, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZD45wrCLlhPV"
   },
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(gamma = 10)\n",
    "modelSVM.fit(trainX, trainY)\n",
    "print(modelSVM.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7TSdxMAlhPb"
   },
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(gamma = 100)\n",
    "modelSVM.fit(trainX, trainY)\n",
    "print(modelSVM.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lh0Dviv-lhPg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekRnZtEjmcDR"
   },
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "07-01-ClassificationAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
