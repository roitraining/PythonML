{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the multiple files into one big CSV since we could not load a large file to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./combine.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in a set of data and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CreditCardFraud.csv')\n",
    "\n",
    "print (df.shape, df.columns)\n",
    "train_size = .3\n",
    "test_size = .1\n",
    "\n",
    "print (df.head())\n",
    "print (df.isFraud.value_counts())\n",
    "print (df.type.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep the columns we want and change the type to code numbers instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'isFraud']\n",
    "df = df[columns]\n",
    "df.type = pd.Categorical(df.type).codes\n",
    "print (df.shape, df.columns)\n",
    "print (df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train & test sets with desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "trainX, testX, trainY, testY = train_test_split(df[df.columns[:-1]], df.isFraud, train_size = train_size, test_size = test_size)\n",
    "print (testY.value_counts())\n",
    "print(trainY.value_counts()/trainY.count())\n",
    "print(testY.value_counts()/testY.count())\n",
    "print (trainX[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelNB = GaussianNB()\n",
    "modelNB.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the results of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = modelNB.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "\n",
    "# helper function to print confusion matrix as percentages\n",
    "def cm_percent(cm, length, legend = True):\n",
    "    import numpy as np\n",
    "    if legend:\n",
    "       print (' PC', 'FP\\n', 'FN', 'PW')\n",
    "    return np.ndarray(shape = (2,2), buffer = np.array([100 *(cm[0][0] + cm[1][1])/length,\n",
    "       100 * cm[0][1]/length, 100 * cm[1][0]/length, 100 * (cm[1][0] + cm[0][1])/length]))\n",
    "\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n",
    "print (testY.value_counts())\n",
    "print (len(testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(modelNB, 'modelNB.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNB2 = load('modelNB.joblib')\n",
    "predY = modelNB2.predict(testX)\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(trainX, trainY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the results of the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(model, columns):\n",
    "    return pd.DataFrame(model.feature_importances_, columns=['Importance'], index = columns).sort_values(['Importance'], ascending = False)\n",
    " \n",
    "predY = modelDT.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "print (cm_percent(cm, len(testY)))\n",
    "print (testY.value_counts(), len(testY))\n",
    "print (important_features(modelDT, trainX.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the accuracy of the predictions and examine important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = modelRF.predict(testX)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print(cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=trainX.columns).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try removing less important features and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrainX = trainX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "newTestX = testX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(newTrainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this case the accuracy did not go up, but in many cases it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = modelRF.predict(newTestX)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print(cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=newTrainX.columns).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "## Logistic Regression requires categorical data be dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "def dummy_code(data, columns, drop_first = True):\n",
    "    for c in columns:\n",
    "        dummies = pd.get_dummies(data[c], prefix = c, drop_first = drop_first)\n",
    "        i = list(data.columns).index(c)\n",
    "        data = pd.concat([data.iloc[:,:i], dummies, data.iloc[:,i+1:]], axis = 1)\n",
    "    return data\n",
    "\n",
    "df2 = dummy_code(df, ['type'], drop_first = True)\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "print (testX.columns)\n",
    "print (testX.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "modelLR.fit(trainX, trainY)\n",
    "print(modelLR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the results of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "predY = modelLR.predict(testX)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "score = modelLR.score(testX, testY)\n",
    "mse = np.mean((predY - testY)**2)\n",
    "print (score, mse)\n",
    "\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n",
    "\n",
    "predY1 = modelLR.predict_proba(testX)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "roc = roc_auc_score(testY, predY)\n",
    "fpr, tpr, x = roc_curve(testY, predY1[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label = 'AUC = ' + str(roc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#import scikitplot.metrics as skplt\n",
    "#import matplotlib.pyplot as plt\n",
    "#skplt.plot_roc(testY, predY1)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Logistic Regression with different probability thresholds to change ratio of false negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = modelLR.predict_proba(testX)\n",
    "print (predY[:10])\n",
    "print ('Score', modelLR.score(testX, testY))\n",
    "\n",
    "for threshold in range(30, 91, 10):\n",
    "    predY1 = np.where(predY[:,1] >= threshold/100, 1, 0)\n",
    "    mse = np.mean((predY1 - testY)**2)\n",
    "    cm = confusion_matrix(testY, predY1)\n",
    "    print ('\\nTHRESHOLD', threshold, 'MSE', mse)\n",
    "    print (cm)\n",
    "    print (cm_percent(cm, len(testY), legend = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for a Neural Network\n",
    "## This time you should not drop the first column when dummy encoding. Additionally, data works better if it is rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "# rescale the data\n",
    "df2 = dummy_code(df, ['type'], drop_first = False)\n",
    "print (df2.columns)\n",
    "df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] /= df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']].max()\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
    "modelNN.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the results of Neural Network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = modelNN.predict(testX)\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print (cm)\n",
    "cmp = cm_percent(cm, len(testY))\n",
    "print (cmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "train_size = .03\n",
    "test_size = .01\n",
    "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "def do_SVM(kernel, gamma):\n",
    "    print (\"\\nKernel:\", kernel, \"Gamma:\", gamma)\n",
    "    modelSVM = svm.SVC(gamma = gamma,  kernel = kernel)\n",
    "    modelSVM.fit(trainX, trainY)\n",
    "    print(modelSVM.score(testX, testY))\n",
    "\n",
    "    predY = modelSVM.predict(testX)\n",
    "    cm = confusion_matrix(testY, predY)\n",
    "    print(cm)\n",
    "\n",
    "do_SVM('linear', gamma='auto')\n",
    "\n",
    "for kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "    for gamma in ['auto', 10, 100]:\n",
    "        if not (kernel == 'poly' and gamma == 100):\n",
    "           do_SVM(kernel, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(gamma = 10)\n",
    "modelSVM.fit(trainX, trainY)\n",
    "print(modelSVM.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(gamma = 100)\n",
    "modelSVM.fit(trainX, trainY)\n",
    "print(modelSVM.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
