{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "07-01-ClassificationAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roitraining/PythonML/blob/Development/Ch07-ClassificationAnalysis/07-01-ClassificationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DftlMhfXlhNI",
        "colab_type": "text"
      },
      "source": [
        "## Combine the multiple files into one big CSV since we could not load a large file to GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79c08g9lhNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ./combine.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCx-mtOzlhNP",
        "colab_type": "text"
      },
      "source": [
        "### Read in a set of data and examine it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKsqCNglhNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('CreditCardFraud.csv')\n",
        "\n",
        "print (df.shape, df.columns)\n",
        "train_size = .3\n",
        "test_size = .1\n",
        "\n",
        "print (df.head())\n",
        "print (df.isFraud.value_counts())\n",
        "print (df.type.value_counts())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mn1AZlPlhNW",
        "colab_type": "text"
      },
      "source": [
        "### Keep the columns we want and change the type to code numbers instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz3S1g6elhNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'isFraud']\n",
        "df = df[columns]\n",
        "df.type = pd.Categorical(df.type).codes\n",
        "print (df.shape, df.columns)\n",
        "print (df.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQQPPfflhNb",
        "colab_type": "text"
      },
      "source": [
        "### Prepare train & test sets with desired columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF8rjfsJlhNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as pp\n",
        "trainX, testX, trainY, testY = train_test_split(df[df.columns[:-1]], df.isFraud, train_size = train_size, test_size = test_size)\n",
        "print (testY.value_counts())\n",
        "print(trainY.value_counts()/trainY.count())\n",
        "print(testY.value_counts()/testY.count())\n",
        "print (trainX[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kusVp-VnlhNg",
        "colab_type": "text"
      },
      "source": [
        "## Create a Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOMjiVP9lhNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "modelNB = GaussianNB()\n",
        "modelNB.fit(trainX, trainY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIHKzxzrlhNm",
        "colab_type": "text"
      },
      "source": [
        "### Examine the results of Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu9BVBrrlhNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predY = modelNB.predict(testX)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "\n",
        "# helper function to print confusion matrix as percentages\n",
        "def cm_percent(cm, length, legend = True):\n",
        "    import numpy as np\n",
        "    if legend:\n",
        "       print (' PC', 'FP\\n', 'FN', 'PW')\n",
        "    return np.ndarray(shape = (2,2), buffer = np.array([100 *(cm[0][0] + cm[1][1])/length,\n",
        "       100 * cm[0][1]/length, 100 * cm[1][0]/length, 100 * (cm[1][0] + cm[0][1])/length]))\n",
        "\n",
        "cmp = cm_percent(cm, len(testY))\n",
        "print (cmp)\n",
        "print (testY.value_counts())\n",
        "print (len(testY))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9_n3marlhNs",
        "colab_type": "text"
      },
      "source": [
        "## Save a trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Zr_8WklhNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(modelNB, 'modelNB.joblib') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJWFouMwlhNw",
        "colab_type": "text"
      },
      "source": [
        "## Load a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMBMLAFOlhNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelNB2 = load('modelNB.joblib')\n",
        "predY = modelNB2.predict(testX)\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "cmp = cm_percent(cm, len(testY))\n",
        "print (cmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnIYVeFzlhN3",
        "colab_type": "text"
      },
      "source": [
        "## Train the Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIMBWf5zlhN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "modelDT = DecisionTreeClassifier()\n",
        "modelDT.fit(trainX, trainY)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6EblXsClhN8",
        "colab_type": "text"
      },
      "source": [
        "## Examine the results of the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB47qZLplhN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def important_features(model, columns):\n",
        "    return pd.DataFrame(model.feature_importances_, columns=['Importance'], index = columns).sort_values(['Importance'], ascending = False)\n",
        " \n",
        "predY = modelDT.predict(testX)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "print (cm_percent(cm, len(testY)))\n",
        "print (testY.value_counts(), len(testY))\n",
        "print (important_features(modelDT, trainX.columns))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEVweEHXlhOB",
        "colab_type": "text"
      },
      "source": [
        "## Create and train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To_f6JTWlhOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelRF = RandomForestClassifier(n_estimators=10)\n",
        "modelRF.fit(trainX, trainY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lycJ3JJZlhOI",
        "colab_type": "text"
      },
      "source": [
        "## Test the accuracy of the predictions and examine important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4yKn4pklhOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predY = modelRF.predict(testX)\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "\n",
        "import pandas as pd\n",
        "feature_imp = pd.Series(modelRF.feature_importances_,index=trainX.columns).sort_values(ascending=False)\n",
        "print (feature_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Iqv4i89lhOM",
        "colab_type": "text"
      },
      "source": [
        "## Visualize important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLly66iulhON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "# Creating a bar plot\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bGX1pYklhOR",
        "colab_type": "text"
      },
      "source": [
        "## Try removing less important features and retrain it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtPKVlDKlhOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newTrainX = trainX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
        "newTestX = testX[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelRF = RandomForestClassifier(n_estimators=10)\n",
        "modelRF.fit(newTrainX, trainY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhtCXClKlhOY",
        "colab_type": "text"
      },
      "source": [
        "### In this case the accuracy did not go up, but in many cases it does"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhFbYZ2slhOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predY = modelRF.predict(newTestX)\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy:\",metrics.accuracy_score(testY, predY))\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "\n",
        "import pandas as pd\n",
        "feature_imp = pd.Series(modelRF.feature_importances_,index=newTrainX.columns).sort_values(ascending=False)\n",
        "print (feature_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFqHSW1nlhOd",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data\n",
        "### Logistic Regression requires categorical data be dummy encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mRaTpXWMlhOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as pp\n",
        "def dummy_code(data, columns, drop_first = True):\n",
        "    for c in columns:\n",
        "        dummies = pd.get_dummies(data[c], prefix = c, drop_first = drop_first)\n",
        "        i = list(data.columns).index(c)\n",
        "        data = pd.concat([data.iloc[:,:i], dummies, data.iloc[:,i+1:]], axis = 1)\n",
        "    return data\n",
        "\n",
        "df2 = dummy_code(df, ['type'], drop_first = True)\n",
        "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
        "\n",
        "print (testX.columns)\n",
        "print (testX.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jje5i7zlhOn",
        "colab_type": "text"
      },
      "source": [
        "## Create a Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hcmFoNIlhOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "modelLR = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
        "modelLR.fit(trainX, trainY)\n",
        "print(modelLR.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQBvfbCilhOt",
        "colab_type": "text"
      },
      "source": [
        "## Examine the results of Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7gJdlFelhOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "predY = modelLR.predict(testX)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "score = modelLR.score(testX, testY)\n",
        "mse = np.mean((predY - testY)**2)\n",
        "print (score, mse)\n",
        "\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "cmp = cm_percent(cm, len(testY))\n",
        "print (cmp)\n",
        "\n",
        "predY1 = modelLR.predict_proba(testX)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "roc = roc_auc_score(testY, predY)\n",
        "fpr, tpr, x = roc_curve(testY, predY1[:,1])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fpr, tpr, label = 'AUC = ' + str(roc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "\n",
        "#import scikitplot.metrics as skplt\n",
        "#import matplotlib.pyplot as plt\n",
        "#skplt.plot_roc(testY, predY1)\n",
        "#plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTgCGR1XlhOy",
        "colab_type": "text"
      },
      "source": [
        "## Try Logistic Regression with different probability thresholds to change ratio of false negatives and positives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CcSOW6YlhOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predY = modelLR.predict_proba(testX)\n",
        "print (predY[:10])\n",
        "print ('Score', modelLR.score(testX, testY))\n",
        "\n",
        "for threshold in range(30, 91, 10):\n",
        "    predY1 = np.where(predY[:,1] >= threshold/100, 1, 0)\n",
        "    mse = np.mean((predY1 - testY)**2)\n",
        "    cm = confusion_matrix(testY, predY1)\n",
        "    print ('\\nTHRESHOLD', threshold, 'MSE', mse)\n",
        "    print (cm)\n",
        "    print (cm_percent(cm, len(testY), legend = False))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2zNQoQblhO6",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data for a Neural Network\n",
        "### This time you should not drop the first column when dummy encoding. Additionally, data works better if it is rescaled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W28T7EjClhO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as pp\n",
        "# rescale the data\n",
        "df2 = dummy_code(df, ['type'], drop_first = False)\n",
        "print (df2.columns)\n",
        "df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] /= df2[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']].max()\n",
        "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcfBRlA8lhPC",
        "colab_type": "text"
      },
      "source": [
        "## Create a Neural Network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HnUlj-TlhPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
        "modelNN.fit(trainX, trainY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyo1DTHYlhPJ",
        "colab_type": "text"
      },
      "source": [
        "## Examine the results of Neural Network predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WD0s5Z0lhPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predY = modelNN.predict(testX)\n",
        "cm = confusion_matrix(testY, predY)\n",
        "print (cm)\n",
        "cmp = cm_percent(cm, len(testY))\n",
        "print (cmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SWOc1o2lhPO",
        "colab_type": "text"
      },
      "source": [
        "## Create a SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNuyggKylhPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "train_size = .03\n",
        "test_size = .01\n",
        "trainX, testX, trainY, testY = train_test_split(df2.iloc[:,df2.columns != 'isFraud'], df2.isFraud, train_size = train_size, test_size = test_size)\n",
        "\n",
        "def do_SVM(kernel, gamma):\n",
        "    print (\"\\nKernel:\", kernel, \"Gamma:\", gamma)\n",
        "    modelSVM = svm.SVC(gamma = gamma,  kernel = kernel)\n",
        "    modelSVM.fit(trainX, trainY)\n",
        "    print (modelSVM.score(testX, testY))\n",
        "\n",
        "    predY = modelSVM.predict(testX)\n",
        "    cm = confusion_matrix(testY, predY)\n",
        "    print (cm)\n",
        "\n",
        "do_SVM('linear', gamma='auto')\n",
        "\n",
        "for kernel in ['rbf', 'poly', 'sigmoid']:\n",
        "    for gamma in ['auto', 10, 100]:\n",
        "        if not (kernel == 'poly' and gamma == 100):\n",
        "           do_SVM(kernel, gamma)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD45wrCLlhPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelSVM = svm.SVC(gamma = 10)\n",
        "modelSVM.fit(trainX, trainY)\n",
        "print(modelSVM.score(testX, testY))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7TSdxMAlhPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelSVM = svm.SVC(gamma = 100)\n",
        "modelSVM.fit(trainX, trainY)\n",
        "print(modelSVM.score(testX, testY))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh0Dviv-lhPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekRnZtEjmcDR",
        "colab_type": "text"
      },
      "source": [
        "# End of notebook"
      ]
    }
  ]
}